{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Linear Regression Project: Predicting NFL Offensive Rankings for 2019-2020 Season"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup as bs \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.linear_model import Lasso, LassoCV, Ridge, RidgeCV\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "import patsy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import f_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Function to pull relevant NFL stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def offense(url):\n",
    "    driver.get(url)\n",
    "    page = driver.page_source\n",
    "    sopa = bs(page)\n",
    "    table = sopa.find('table', {'id':'team_stats'})\n",
    "    ranker=list(filter(None,[tr.find('th', {'data-stat':\"ranker\"}).text for tr in table.find_all('tr') if tr.find('th', {'data-stat':\"ranker\"})!= None]))[1:]\n",
    "    team=list(filter(None,[tr.find('td', {'data-stat':\"team\"}).text for tr in table.find_all('tr') if tr.find('td', {'data-stat':\"team\"})!= None]))[:-3] \n",
    "    team_name_cleaned=[name.split()[-1] for name in team]\n",
    "    points=list(filter(None,[tr.find('td', {'data-stat':\"points\"}).text for tr in table.find_all('tr') if tr.find('td', {'data-stat':\"points\"})!= None]))[:-3]\n",
    "    tot_yds=list(filter(None,[tr.find('td', {'data-stat':\"total_yards\"}).text for tr in table.find_all('tr') if tr.find('td', {'data-stat':\"total_yards\"})!= None]))[:-3]  \n",
    "    first_down=list(filter(None,[tr.find('td', {'data-stat': \"first_down \"}).text for tr in table.find_all('tr') if tr.find('td', {'data-stat': \"first_down \"})!= None]))[:-3]  \n",
    "    pass_att=list(filter(None,[tr.find('td', {'data-stat': \"pass_att \"}).text for tr in table.find_all('tr') if tr.find('td', {'data-stat': \"pass_att \"})!= None]))[:-3]  \n",
    "    pass_td=list(filter(None,[tr.find('td', {'data-stat': \"pass_td \"}).text for tr in table.find_all('tr') if tr.find('td', {'data-stat': \"pass_td \"})!= None]))[:-3]  \n",
    "    pass_int=list(filter(None,[tr.find('td', {'data-stat': \"pass_int \"}).text for tr in table.find_all('tr') if tr.find('td', {'data-stat': \"pass_int \"})!= None]))[:-3]  \n",
    "    pnypa=list(filter(None,[tr.find('td', {'data-stat': \"pass_net_yds_per_att \"}).text for tr in table.find_all('tr') if tr.find('td', {'data-stat': \"pass_net_yds_per_att \"})!= None]))[:-3]  \n",
    "    rush_att=list(filter(None,[tr.find('td', {'data-stat': \"rush_att \"}).text for tr in table.find_all('tr') if tr.find('td', {'data-stat': \"rush_att \"})!= None]))[:-3]  \n",
    "    rush_td=list(filter(None,[tr.find('td', {'data-stat': \"rush_td \"}).text for tr in table.find_all('tr') if tr.find('td', {'data-stat': \"rush_td \"})!= None]))[:-3]  \n",
    "    score_pct=list(filter(None,[tr.find('td', {'data-stat': \"score_pct \"}).text for tr in table.find_all('tr') if tr.find('td', {'data-stat': \"score_pct \"})!= None]))[:-3]  \n",
    "    turnover_pct=list(filter(None,[tr.find('td', {'data-stat': \"turnover_pct \"}).text for tr in table.find_all('tr') if tr.find('td', {'data-stat': \"turnover_pct \"})!= None]))[:-3]  \n",
    "    exp_pts_tot=list(filter(None,[tr.find('td', {'data-stat': \"exp_pts_tot \"}).text for tr in table.find_all('tr') if tr.find('td', {'data-stat': \"exp_pts_tot \"})!= None]))  \n",
    "    stats_zipped=[list(a) for a in zip(ranker, points, tot_yds, first_down, pass_att, pass_td, pass_int, pnypa, rush_att, rush_td, score_pct, turnover_pct,exp_pts_tot)]  \n",
    "    kick_table = sopa.find('div', {'id':'all_kicking'})  \n",
    "    kick_team=list(filter(None,[tr.find('td', {'data-stat': \"team \"}).text for tr in kick_table.find_all('tr') if tr.find('td', {'data-stat': \"team \"})!= None]))[:-3]  \n",
    "    kick_team_cleaned=[name.split()[-1] for name in kick_team]  \n",
    "    kick_goals=list(filter(None,[tr.find('td', {'data-stat': \"fgm \"}).text for tr in kick_table.find_all('tr') if tr.find('td', {'data-stat': \"fgm \"})!= None]))[:-3]  \n",
    "    kick_zip=list(zip(kick_team_cleaned, kick_goals))  \n",
    "    offense_dict=dict(zip(team_name_cleaned,stats_zipped))  \n",
    "    for k, v in offense_dict.items():  \n",
    "        for item in kick_zip:  \n",
    "            if item[0]==k:  \n",
    "                v.append(item[1])  \n",
    "    return offense_dict  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Functions for Pass 5 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offense2018_dict=offense('https://www.pro-football-reference.com/years/2018/index.htm')\n",
    "offense2017_dict=offense('https://www.pro-football-reference.com/years/2017/index.htm')\n",
    "offense2016_dict=offense('https://www.pro-football-reference.com/years/2016/index.htm')\n",
    "offense2015_dict=offense('https://www.pro-football-reference.com/years/2016/index.htm')\n",
    "offense2014_dict=offense('https://www.pro-football-reference.com/years/2014/index.htm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Function for Positional Spending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_spending(string): \n",
    "    otc_url = 'https://overthecap.com/positional-spending/' \n",
    "    response = requests.get(otc_url) \n",
    "    page = response.text \n",
    "    sopa = BeautifulSoup(page,  \"lxml \") \n",
    "    pos_dic={} \n",
    "    pos_list=over_the_cap_sopa.find( \"div \", { \"id \" : string}) \n",
    "    extract_pos = [ele.text for ele in pos_list.findAll('td', { \"class \" :  \"sortable \"})] \n",
    "    sub_list = [extract_pos[i * 12:(i + 1) * 12] for i in range((len(extract_pos) + 12 - 1) // 12 )]  \n",
    "    for i in sub_list: \n",
    "        pos_dic[i[0]]=i[1:6] \n",
    "    return pos_dic "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Positional Spending Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_spend2014_dic=positional_spending( \"y2014 \")\n",
    "pos_spend2015_dic=positional_spending( \"y2015 \")\n",
    "pos_spend2016_dic=positional_spending( \"y2016 \")\n",
    "pos_spend2017_dic=positional_spending( \"y2017 \")\n",
    "pos_spend2018_dic=positional_spending( \"y2018 \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dictionary for Offence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def off_dict(dictionary): \n",
    "    columns=['Rank', 'Points_For', 'Total_Yds', 'First_Down','Pass_Att', 'Pass_TD', 'Pass_Int', 'PNYPA', 'Rush_Att', 'Rush_TD', 'Score%','TO%', 'EXP', 'FGM'] \n",
    "    offense_df=pd.DataFrame.from_dict(dictionary, orient='index', columns=columns) \n",
    "    return offense_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offense2018_df=off_dict(offense2018_dict)\n",
    "offense2017_df=off_dict(offense2017_dict)\n",
    "offense2016_df=off_dict(offense2016_dict)\n",
    "offense2015_df=off_dict(offense2015_dict)\n",
    "offense2014_df=off_dict(offense2014_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_spend_df2018=ps_dict(pos_spend2018_dic) \n",
    "pos_spend_df2018['Year']='2018' \n",
    "pos_spend_df2017=ps_dict(pos_spend2017_dic) \n",
    "pos_spend_df2017['Year']='2017' \n",
    "pos_spend_df2016=ps_dict(pos_spend2016_dic) \n",
    "pos_spend_df2016['Year']='2016' \n",
    "pos_spend_df2015=ps_dict(pos_spend2015_dic) \n",
    "pos_spend_df2015['Year']='2015' \n",
    "pos_spend_df2014=ps_dict(pos_spend2014_dic) \n",
    "pos_spend_df2014['Year']='2014' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate Dictionaries into one Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat(df1, df2):\n",
    "    comb=pd.concat([df1, df2], axis=1)\n",
    "    return comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df=pd.concat([concat(offense2018_df, pos_spend_df2018), concat(offense2017_df, pos_spend_df2017), concat(offense2016_df, pos_spend_df2016), concat(offense2015_df, pos_spend_df2015), concat(offense2014_df, pos_spend_df2014)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_char=['QB','RB','WR','TE','OL']\n",
    "stringToint=['Rank','Points_For','Total_Yds','First_Down','Pass_Att','Pass_TD','Pass_Int','PNYPA','Rush_Att','Rush_TD', 'Score%', 'TO%', 'EXP', 'QB','RB','WR','TE','OL', 'FGM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove $ and ,: \n",
    "for column in remove_char: \n",
    "    final_df[column]=final_df[column].apply(lambda x: x.strip('$').replace(',', '')) \n",
    "     \n",
    "#Convert String to Int \n",
    "for column in stringToint: \n",
    "    final_df[column]=pd.to_numeric(final_df[column]) \n",
    "     \n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pass to Rush Att Ratio  \n",
    "final_df[ \"Pass_Att_Per \"]= round(final_df[ \"Pass_Att \"]/(final_df[ \"Pass_Att \"]+final_df[ \"Rush_Att \"]), 2)  \n",
    "final_df[ \"Rush_Att_Per \"]= round(final_df[ \"Rush_Att \"]/(final_df[ \"Pass_Att \"]+final_df[ \"Rush_Att \"]), 2)  \n",
    "final_df['PassTD_Cost']=round(final_df[ \"QB \"]/final_df[ \"Pass_TD \"], 2)  \n",
    "final_df['RushTD_Cost']=round(final_df[ \"RB \"]/final_df[ \"Pass_TD \"], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get general info on Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df=pd.get_dummies(final_df)\n",
    "final_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression to Predict Target [Rank]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x=final_df[[ 'OL','WR','TE','EXP','Pass_Att_Per','Pass_Att','Rush_Att_Per', 'Rush_Att','PassTD_Cost','RushTD_Cost','Year_2014','Year_2015', 'Year_2016','Year_2017' ,'Year_2018']]\n",
    "y=final_df['Rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, Test, Split\"\n",
    "# hold out 20% of the data for final testing\n",
    "x, X_test, y, y_test = train_test_split(x, y, test_size=.2, random_state=10) \n",
    " \n",
    "lin = lr() \n",
    " \n",
    "scaler = StandardScaler() \n",
    " \n",
    "X_train, X_val, y_train, y_val =  \n",
    "        train_test_split(x, y, test_size=.20, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature scaling for train, val, and test so that we can run our ridge model on each\\n\",\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "lm_reg = LassoCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_reg.fit(X_train_scaled, y_train)\n",
    "print(f'Lasso Regression (Test) R^2: {lm_reg.score(X_test_scaled, y_test):.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
